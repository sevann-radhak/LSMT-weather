{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../data/weather_dataset_preprocesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the 50% of the data\n",
    "df = df[:int(len(df)//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'T (degC)'\n",
    "target_index = 'datetime'\n",
    "load = df[target_column]\n",
    "time = df[target_index]\n",
    "x_label = 'Time'\n",
    "y_label = 'Temperature (°C)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(time[:673], load[:673], color='k', label='Real', linewidth=0.4)\n",
    "plt.xticks(np.arange(0, 673, step=168))\n",
    "plt.xlabel(xlabel=x_label)\n",
    "plt.ylabel(ylabel=y_label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load[:int(len(load) * 0.8)]\n",
    "test = load[int(len(load) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train, label='Train', color='b', linewidth=0.3)\n",
    "plt.plot(test, label='Test', color='g', linewidth=0.3)\n",
    "plt.xlabel(xlabel=x_label)\n",
    "plt.ylabel(ylabel=y_label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    df_train[\"lag{}\".format(i)] = df_train[target_column].shift(i)\n",
    "    df_test[\"lag{}\".format(i)] = df_test[target_column].shift(i)\n",
    "\n",
    "df_train = df_train.bfill().drop(columns=[target_column])\n",
    "df_test = df_test.bfill().drop(columns=[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEMD\n",
    "imf_eemd = emd.sift.ensemble_sift(np.array(train), nensembles=4, nprocesses=6, ensemble_noise=1, imf_opts={'sd_thresh': 0.1})\n",
    "emd.plotting.plot_imfs(imf_eemd)\n",
    "imf_eemd_df = pd.DataFrame(data=imf_eemd)\n",
    "imf_eemd_df.columns = ['imf_eemd_{}'.format(i + 1) for i in range(0, imf_eemd.shape[1])]\n",
    "display(imf_eemd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización y preparación de datos para LSTM\n",
    "def prepare_data(series):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(1, len(scaled_data)):\n",
    "        X.append(scaled_data[i-1:i, 0])\n",
    "        y.append(scaled_data[i, 0])\n",
    "        \n",
    "    return np.array(X), np.array(y), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del modelo\n",
    "c = 10\n",
    "d = 1\n",
    "epochs = 8\n",
    "test_length = len(test)\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de modelos LSTM para IMFs 1 al 7\n",
    "# IMF 1\n",
    "imf1_eemd_lstm_X, imf1_eemd_lstm_y, scaler1 = prepare_data(imf_eemd_df['imf_eemd_1'])\n",
    "imf1_eemd_lstm_X = imf1_eemd_lstm_X.reshape((imf1_eemd_lstm_X.shape[0], 1, imf1_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(c, activation='relu', input_shape=(imf1_eemd_lstm_X.shape[1], imf1_eemd_lstm_X.shape[2])))\n",
    "model1.add(Dense(d))\n",
    "model1.compile(optimizer='adam', loss='mse')\n",
    "model1.fit(imf1_eemd_lstm_X, imf1_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf1_eemd_lstm_fc = model1.predict(imf1_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf1_eemd_lstm_fc = scaler1.inverse_transform(imf1_eemd_lstm_fc)\n",
    "\n",
    "# IMF 2\n",
    "imf2_eemd_lstm_X, imf2_eemd_lstm_y, scaler2 = prepare_data(imf_eemd_df['imf_eemd_2'])\n",
    "imf2_eemd_lstm_X = imf2_eemd_lstm_X.reshape((imf2_eemd_lstm_X.shape[0], 1, imf2_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(c, activation='relu', input_shape=(imf2_eemd_lstm_X.shape[1], imf2_eemd_lstm_X.shape[2])))\n",
    "model2.add(Dense(d))\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "model2.fit(imf2_eemd_lstm_X, imf2_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf2_eemd_lstm_fc = model2.predict(imf2_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf2_eemd_lstm_fc = scaler2.inverse_transform(imf2_eemd_lstm_fc)\n",
    "\n",
    "# IMF 3\n",
    "imf3_eemd_lstm_X, imf3_eemd_lstm_y, scaler3 = prepare_data(imf_eemd_df['imf_eemd_3'])\n",
    "imf3_eemd_lstm_X = imf3_eemd_lstm_X.reshape((imf3_eemd_lstm_X.shape[0], 1, imf3_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(c, activation='relu', input_shape=(imf3_eemd_lstm_X.shape[1], imf3_eemd_lstm_X.shape[2])))\n",
    "model3.add(Dense(d))\n",
    "model3.compile(optimizer='adam', loss='mse')\n",
    "model3.fit(imf3_eemd_lstm_X, imf3_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf3_eemd_lstm_fc = model3.predict(imf3_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf3_eemd_lstm_fc = scaler3.inverse_transform(imf3_eemd_lstm_fc)\n",
    "\n",
    "# IMF 4\n",
    "imf4_eemd_lstm_X, imf4_eemd_lstm_y, scaler4 = prepare_data(imf_eemd_df['imf_eemd_4'])\n",
    "imf4_eemd_lstm_X = imf4_eemd_lstm_X.reshape((imf4_eemd_lstm_X.shape[0], 1, imf4_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(c, activation='relu', input_shape=(imf4_eemd_lstm_X.shape[1], imf4_eemd_lstm_X.shape[2])))\n",
    "model4.add(Dense(d))\n",
    "model4.compile(optimizer='adam', loss='mse')\n",
    "model4.fit(imf4_eemd_lstm_X, imf4_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf4_eemd_lstm_fc = model4.predict(imf4_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf4_eemd_lstm_fc = scaler4.inverse_transform(imf4_eemd_lstm_fc)\n",
    "\n",
    "# IMF 5\n",
    "imf5_eemd_lstm_X, imf5_eemd_lstm_y, scaler5 = prepare_data(imf_eemd_df['imf_eemd_5'])\n",
    "imf5_eemd_lstm_X = imf5_eemd_lstm_X.reshape((imf5_eemd_lstm_X.shape[0], 1, imf5_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(c, activation='relu', input_shape=(imf5_eemd_lstm_X.shape[1], imf5_eemd_lstm_X.shape[2])))\n",
    "model5.add(Dense(d))\n",
    "model5.compile(optimizer='adam', loss='mse')\n",
    "model5.fit(imf5_eemd_lstm_X, imf5_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf5_eemd_lstm_fc = model5.predict(imf5_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf5_eemd_lstm_fc = scaler5.inverse_transform(imf5_eemd_lstm_fc)\n",
    "\n",
    "# IMF 6\n",
    "imf6_eemd_lstm_X, imf6_eemd_lstm_y, scaler6 = prepare_data(imf_eemd_df['imf_eemd_6'])\n",
    "imf6_eemd_lstm_X = imf6_eemd_lstm_X.reshape((imf6_eemd_lstm_X.shape[0], 1, imf6_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(LSTM(c, activation='relu', input_shape=(imf6_eemd_lstm_X.shape[1], imf6_eemd_lstm_X.shape[2])))\n",
    "model6.add(Dense(d))\n",
    "model6.compile(optimizer='adam', loss='mse')\n",
    "model6.fit(imf6_eemd_lstm_X, imf6_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf6_eemd_lstm_fc = model6.predict(imf6_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf6_eemd_lstm_fc = scaler6.inverse_transform(imf6_eemd_lstm_fc)\n",
    "\n",
    "# IMF 7\n",
    "imf7_eemd_lstm_X, imf7_eemd_lstm_y, scaler7 = prepare_data(imf_eemd_df['imf_eemd_7'])\n",
    "imf7_eemd_lstm_X = imf7_eemd_lstm_X.reshape((imf7_eemd_lstm_X.shape[0], 1, imf7_eemd_lstm_X.shape[1]))\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(LSTM(c, activation='relu', input_shape=(imf7_eemd_lstm_X.shape[1], imf7_eemd_lstm_X.shape[2])))\n",
    "model7.add(Dense(d))\n",
    "model7.compile(optimizer='adam', loss='mse')\n",
    "model7.fit(imf7_eemd_lstm_X, imf7_eemd_lstm_y, epochs=epochs, verbose=verbose)\n",
    "imf7_eemd_lstm_fc = model7.predict(imf7_eemd_lstm_X[-len(test):].reshape((len(test), 1, 1)))\n",
    "imf7_eemd_lstm_fc = scaler7.inverse_transform(imf7_eemd_lstm_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "imf8_eemd_arima = ARIMA(imf_eemd_df['imf_eemd_8'], order=(2, 1, 0)).fit()\n",
    "imf8_eemd_arima_fc = imf8_eemd_arima.forecast(steps=len(test))\n",
    "\n",
    "imf9_eemd_arima = ARIMA(imf_eemd_df['imf_eemd_9'], order=(2, 1, 0)).fit()\n",
    "imf9_eemd_arima_fc = imf9_eemd_arima.forecast(steps=len(test))\n",
    "\n",
    "imf10_eemd_arima = ARIMA(imf_eemd_df['imf_eemd_10'], order=(2, 1, 0)).fit()\n",
    "imf10_eemd_arima_fc = imf10_eemd_arima.forecast(steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf1_eemd_lstm_fc_1 = imf1_eemd_lstm_fc.reshape(-1)\n",
    "imf2_eemd_lstm_fc_2 = imf2_eemd_lstm_fc.reshape(-1)\n",
    "imf3_eemd_lstm_fc_3 = imf3_eemd_lstm_fc.reshape(-1)\n",
    "imf4_eemd_lstm_fc_4 = imf4_eemd_lstm_fc.reshape(-1)\n",
    "imf5_eemd_lstm_fc_5 = imf5_eemd_lstm_fc.reshape(-1)\n",
    "imf6_eemd_lstm_fc_6 = imf6_eemd_lstm_fc.reshape(-1)\n",
    "imf7_eemd_lstm_fc_7 = imf7_eemd_lstm_fc.reshape(-1)\n",
    "\n",
    "imf_lstm_fc = np.sum([\n",
    "    imf1_eemd_lstm_fc_1, imf2_eemd_lstm_fc_2, imf3_eemd_lstm_fc_3,\n",
    "    imf4_eemd_lstm_fc_4, imf5_eemd_lstm_fc_5, imf6_eemd_lstm_fc_6, imf7_eemd_lstm_fc_7,\n",
    "    imf8_eemd_arima_fc, imf9_eemd_arima_fc, imf10_eemd_arima_fc\n",
    "], axis=0)\n",
    "\n",
    "print(imf_lstm_fc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(imf_lstm_fc, label='predict', color='r', linewidth=0.5)\n",
    "plt.plot(test.values, label='actual', color='k', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "RMSE_EEMD_LSTM = mean_squared_error(test, imf_lstm_fc, squared=False)\n",
    "MAE_EEMD_LSTM = mean_absolute_error(test, imf_lstm_fc)\n",
    "MAPE_EEMD_LSTM = mean_absolute_percentage_error(test, imf_lstm_fc)\n",
    "\n",
    "print('RMSE = {}'.format(RMSE_EEMD_LSTM), \n",
    "      '\\nMAE = {}'.format(MAE_EEMD_LSTM), \n",
    "      '\\nMAPE = {}'.format(MAPE_EEMD_LSTM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "def objective_function(params):\n",
    "    a, b, c, d, e, f, g, h, i, j = params\n",
    "    imf_lstm_fc = np.sum([\n",
    "        a * imf1_eemd_lstm_fc_1, b * imf2_eemd_lstm_fc_2, c * imf3_eemd_lstm_fc_3,\n",
    "        d * imf4_eemd_lstm_fc_4, e * imf5_eemd_lstm_fc_5, f * imf6_eemd_lstm_fc_6, g * imf7_eemd_lstm_fc_7,\n",
    "        h * imf8_eemd_arima_fc, i * imf9_eemd_arima_fc, j * imf10_eemd_arima_fc\n",
    "    ], axis=0)\n",
    "    return mean_squared_error(test, imf_lstm_fc, squared=False)\n",
    "\n",
    "bounds = [(0, 1)] * 10\n",
    "\n",
    "res = differential_evolution(objective_function, bounds, maxiter=1000, disp=True)\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(imf_lstm_fc + res.x[0], label='predict', color='r', linewidth=0.5)\n",
    "plt.plot(test.values, label='actual', color='k', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "RMSE_EEMD_LSTM = mean_squared_error(test, imf_lstm_fc + res.x[0], squared=False)\n",
    "MAE_EEMD_LSTM = mean_absolute_error(test, imf_lstm_fc + res.x[0])\n",
    "MAPE_EEMD_LSTM = mean_absolute_percentage_error(test, imf_lstm_fc + res.x[0])\n",
    "\n",
    "print('RMSE = {}'.format(RMSE_EEMD_LSTM), \n",
    "      '\\nMAE = {}'.format(MAE_EEMD_LSTM), \n",
    "      '\\nMAPE = {}'.format(MAPE_EEMD_LSTM))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
